{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>\ud83c\udf1f With Paradigm, you ML code is production-ready from the beginning</p> <p>Paradigm is a light-weight, lightning-fast, supremely adaptable tool, effortlessly packaging your ML code into robust pipelines for seamless deployment on Kubernetes. Bypass the need for code refactoring as Paradigm intelligently interprets your Python notebooks and scripts, priming them for scalable production. Paradigm is your ultimate ally in ML deployment, merging unparalleled speed, adaptability, and simplicity into one package.</p> <p>Official website - paradigmai.net</p>"},{"location":"#paradigm-in-action","title":"Paradigm in Action","text":""},{"location":"#terminal-view","title":"Terminal View","text":""},{"location":"#dag-view","title":"DAG View","text":""},{"location":"#deploy-an-ml-pipeline-in-just-2-steps","title":"Deploy an ML pipeline in just 2 steps","text":"<pre><code>$ paradigm launch --step &lt;your-project-notebooks-or-scripts&gt;\n$ paradigm deploy\n</code></pre>"},{"location":"Installation/Locally/","title":"Try Locally \ud83d\udcbb","text":"<p>You need a Kubernetes cluster and <code>kubectl</code> set up to be able to access that cluster. For this to run locally, we recommend using <code>minikube</code>. - Please refer to the minikube documentation</p>"},{"location":"Installation/Locally/#set-up-paradigm","title":"Set up Paradigm","text":"<ul> <li>(Recommended) Create a new Python environment with your preferred environment manager</li> <li>Clone this repo <ul> <li><code>git clone https://github.com/ParadigmAI/paradigm.git</code></li> </ul> </li> <li>Go into the directory <ul> <li><code>cd paradigm</code></li> </ul> </li> <li>Make the installation script executable <ul> <li><code>chmod +x install.sh</code></li> </ul> </li> <li>Run the intallation script <ul> <li><code>./install.sh</code></li> </ul> </li> <li>Validate if paradigm was properly installed<ul> <li><code>paradigm --help</code></li> </ul> </li> </ul>"},{"location":"Installation/Locally/#now-lets-move-into-your-ml-project-folder","title":"Now let's move into your ML project folder","text":"<p>Your folder can contain one or more scripts or Python notebooks that you want to execute as steps in an ML pipeline.</p> <ul> <li>First, let's configure your current terminal session to use the Docker daemon inside the Minikube environment instead of the default Docker daemon on your host machine. This eliminated the need for an image registry when working locally.<ul> <li><code>eval $(minikube docker-env)</code></li> </ul> </li> </ul> <p>From here we follow a basic example project just to make it easier to exaplin the commands. Please change the necessary parameters according to your project - The preferred directory structure should be as follows. In the below example, <code>p1, p2 and p3</code> represent the names of the python scripts or notebooks you have. (Refer the examples/basic)     - IMPORTANT - Note the <code>requirements.&lt;file name&gt;</code> files. You have to create a txt with that specific naming only for the scripts or notebooks that have additional dependencies. It becomes the <code>requirements.txt</code> for that step. We promise this is the only file addition before taking your ML code to prodution.     - Example:</p> <pre><code>    - \ud83d\udcc1 project_root\n        - \ud83d\udcc4 p1.py\n        - \ud83d\udcc4 p2.ipynb\n        - \ud83d\udcc4 p3.py\n        - \ud83d\udcc4 requirements.p1\n        - \ud83d\udcc4 requirements.p3\n</code></pre> <ul> <li>Now we are ready to let Paradigm get things ready before deploying to Kubernetes. Include the scripts/notebook you want as steps in the below command. This command basically containerizes your code.</li> </ul> <pre><code>paradigm launch --steps p1 p2 p3\n</code></pre> <ul> <li>As the final step, deploy the pipeline with the below command.</li> </ul> <pre><code>paradigm deploy --steps p1 p2 --dependencies \"p2:p1,p3:p2|p1\" --deployment p3 --deployment_port 8000 --output workflow.yaml --name pipeline1\n</code></pre> <ul> <li> <p>In the above command: </p> <ul> <li><code>--steps</code> should speicify all steps, except any step that should be run as a service, e.g., an API endpoint. </li> <li><code>--dependencies \"p2:p1,p3:p2|p1\"</code> defines the graph stucture (DAG) on how the steps should be run. In this example, we are stating that step <code>p2</code> is dependent on <code>p1</code> and step <code>p3</code> is dependent on both <code>p2</code> and <code>p1</code>. </li> <li><code>--deployment p3</code> defines a service that needs to be run at the end of the pipeline. Hence, we don't mention is under <code>--steps</code>. </li> <li><code>--deployment_port</code> is defined if the above service is exposed via a specific port internally. </li> <li><code>--name</code> can be any name that you want to give this particualr pipeline</li> </ul> </li> <li> <p>(OPTIONAL) You can use Argo UI to observe all pipelines and get logs. For that, first make it accessible via your browser by running the below command. </p> <ul> <li><code>kubectl -n paradigm port-forward deployment/argo-server 2746:2746</code></li> <li>Now I your local browser, go to <code>http://localhost:2746</code></li> </ul> </li> <li> <p>(OPTIONAL) To access the service that is deployed in the previous set (for example an API endpoint), run the following code since we're working inside minikube. </p> <ul> <li><code>minikube service deploy-p3 -n paradigm</code></li> </ul> </li> <li> <p>(OPTIONAL) In case you want to delete the running service and deployment, use the following commands. <code>&lt;deployment_step&gt;</code> is the name of the file that has the deolyment code.</p> <ul> <li><code>kubectl delete deployment deploy-&lt;deployment_step&gt; -n paradigm</code></li> <li><code>kubectl delete service deploy-&lt;deployment_step&gt; -n paradigm</code></li> </ul> </li> </ul>"},{"location":"Installation/On_AWS/","title":"To Deploy in AWS \u2601\ufe0f","text":"<p>You need a Kubernetes cluster and <code>kubectl</code> set up to be able to access that cluster. On AWS, we use Amazon Elastic Kubernetes Service (Amazon EKS) for this.  - Please refer to the Amazon EKS on how to set things up - Make sure you can AWS CLI installed and configured as well</p> <p>Also, make sure Docker is installed and running in your environment</p>"},{"location":"Installation/On_AWS/#set-up-paradigm","title":"Set up Paradigm","text":"<p>In a terminal with the above kubectl access, follow the below steps.</p> <ul> <li>(Recommended) Create a new Python environment with your preferred environment manager</li> <li>Clone this repo <ul> <li><code>git clone https://github.com/ParadigmAI/paradigm.git</code></li> </ul> </li> <li>Go into the directory <ul> <li><code>cd paradigm</code></li> </ul> </li> <li>Make the installation script executable <ul> <li><code>chmod +x install-aws.sh</code></li> </ul> </li> <li>Run the intallation script <ul> <li><code>./install-aws.sh</code></li> </ul> </li> <li>Validate if paradigm was properly installed<ul> <li><code>paradigm --help</code></li> </ul> </li> </ul>"},{"location":"Installation/On_AWS/#now-lets-move-into-your-ml-project-folder","title":"Now let's move into your ML project folder","text":"<p>Your folder can contain one or more scripts/notebooks that you want to execute as steps in an ML pipeline.</p> <p>From here we follow a basic example project just to make it easier to exaplin the commands. Please change the necessary parameters according to your project - The preferred directory structure should be as follows. In the below example, <code>p1, p2 and p3</code> represent the names of the python scripts or notebooks you have. (Refer the examples/basic)     - IMPORTANT - Note the <code>requirements.&lt;file name&gt;</code> files. You have to create a txt with that specific naming only for the scripts or notebooks that have additional dependencies. It becomes the <code>requirements.txt</code> for that step. We promise this is the only file addition before taking your ML code to prodution.     - Example:</p> <pre><code>    - \ud83d\udcc1 project_root\n        - \ud83d\udcc4 p1.py\n        - \ud83d\udcc4 p2.ipynb\n        - \ud83d\udcc4 p3.py\n        - \ud83d\udcc4 requirements.p1\n        - \ud83d\udcc4 requirements.p3\n</code></pre> <ul> <li>Now we are ready to let Paradigm get things ready before deploying to Kubernetes. Include the scripts/notebook you want as steps in the below command. This command basically containerizes your code.</li> </ul> <pre><code>paradigm launch --steps p1 p2 p3 --region_name us-east-1\n</code></pre> <ul> <li>As the final step, deploy the pipeline with the below command.</li> </ul> <pre><code>paradigm deploy --steps p1 p2 --dependencies \"p2:p1,p3:p2|p1\" --deployment p3 --deployment_port 8000 --deployment_memory 2Gi --output workflow.yaml --name pipe1 --region_name us-east-1\n</code></pre> <ul> <li> <p>In the above command: </p> <ul> <li><code>--steps</code> should speicify all steps, except any step that should be run as a service, e.g., an API endpoint. </li> <li><code>--dependencies \"p2:p1,p3:p2|p1\"</code> defines the graph stucture (DAG) on how the steps should be run. In this example, we are stating that step <code>p2</code> is dependent on <code>p1</code> and step <code>p3</code> is dependent on both <code>p2</code> and <code>p1</code>. </li> <li><code>--deployment p3</code> defines a service that needs to be run at the end of the pipeline. Hence, we don't mention is under <code>--steps</code>. </li> <li><code>--deployment_port</code> is defined if the above service is exposed via a specific port internally. </li> <li><code>--deployment_memory</code> is to specify the amount of memory required for the deployment step</li> <li><code>--name</code> can be any name that you want to give this particualr pipeline</li> <li><code>--region_name</code> is the aws region that you want to use</li> </ul> </li> <li> <p>(OPTIONAL) You can use Argo UI to observe all pipelines and get logs. For that, first make it accessible via your browser by running the below command. </p> <ul> <li><code>kubectl -n paradigm port-forward deployment/argo-server 2746:2746</code></li> <li>Now I your local browser, go to <code>http://localhost:2746</code></li> </ul> </li> <li> <p>(OPTIONAL) In case you want to delete the running service and deployment, use the following commands. <code>&lt;deployment_step&gt;</code> is the make of the file that has the deolyment code.</p> <ul> <li><code>kubectl delete deployment deploy-&lt;deployment_step&gt; -n paradigm</code></li> <li><code>kubectl delete service deploy-&lt;deployment_step&gt; -n paradigm</code></li> </ul> </li> </ul>"},{"location":"Installation/Video_tutorial/","title":"Video Tutorial","text":""},{"location":"Support/Reach_out/","title":"Reach out","text":"<p>Email - Contact Us</p> <p>Official website - paradigmai.net</p>"},{"location":"Tutorials/basic_pipeline/","title":"Basic Pipeline","text":"<p>Code: example/basic</p> <p>The basic pipeline is only meant to demonstrate how multiple Python scripts and notebooks can be seamlessly chained togther to form a pipeline using Paradigm. In practice, these files can perform tasks such as data handling, model trainging/evaluation and model deployment. </p> <p>In the example/basic directory you will find three files that will be steps in the basic pipeline.</p> <pre><code>    - \ud83d\udcc1 example/basic\n        - \ud83d\udcc4 p1.py\n        - \ud83d\udcc4 p2.ipynb\n        - \ud83d\udcc4 p3.py\n        - \ud83d\udcc4 requirements.p3\n</code></pre> <p>Here, <code>p1</code> is a python script, <code>p2</code> is an iPython notebook and <code>p3</code> is a simple FastAPI example. </p> <p>Note the <code>requirements.p3</code> file where we have the necessary dependencies for the script <code>p3</code>. These requirement files shoudl only be added if a script or a notebook needs additional dependecies. </p> <ul> <li>First, pipeline is lauched with the below command</li> </ul> <pre><code>paradigm launch --steps p1 p2 p3 --region_name us-east-1\n</code></pre> <p>This commands basically takes care of containerizing the scripts and notebooks provided under <code>--steps</code> and uploading them to a specified container registry (a container registry is not used for local deployements).</p> <ul> <li>Next, we execute the pipeline with the below command</li> </ul> <pre><code>paradigm deploy --steps p1 p2 --dependencies \"p2:p1,p3:p2|p1\" --deployment p3 --deployment_port 8000 --deployment_memory 2Gi --output workflow.yaml --name pipeline1 --region_name us-east-1\n</code></pre> <p><code>--steps</code> should speicify all steps, except any step that should be run as a service, e.g., an API endpoint. </p> <p><code>--dependencies \"p2:p1,p3:p2|p1\"</code> defines the graph stucture (DAG) on how the steps should be run. In this example, we are stating that step <code>p2</code> is dependent on <code>p1</code> and step <code>p3</code> is dependent on both <code>p2</code> and <code>p1</code>. </p> <p><code>--deployment p3</code> defines a service that needs to be run at the end of the pipeline. Hence, we don't mention is under <code>--steps</code>. </p> <p><code>--deployment_port</code> is defined if the above service is exposed via a specific port internally. </p> <p><code>--deployment_memory</code> is to specify the amount of memory required for the deployment step</p> <p><code>--name</code> can be any name that you want to give this particualr pipeline</p> <p>With that, we are done!</p> <p>You can use Argo UI to observe all pipelines and get logs. For that, first make it accessible via your browser by running the below command. </p> <p><code>kubectl -n paradigm port-forward deployment/argo-server 2746:2746</code></p> <p>Now in your local browser, go to <code>http://localhost:2746</code></p> <p>To access the service that is deployed in the previous set (for example an API endpoint), run the following code since we're working inside minikube. </p> <pre><code>- `minikube service deploy-p3 -n paradigm`\n</code></pre> <p>In case you want to delete the running service and deployment, use the following commands. <code>&lt;deployment_step&gt;</code> is the name of the file that has the deolyment code.</p> <p><code>kubectl delete deployment deploy-p3 -n paradigm</code></p> <p><code>kubectl delete service deploy-p3 -n paradigm</code></p>"}]}